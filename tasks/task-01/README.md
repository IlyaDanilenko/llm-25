# Лаба 1 — Развёртывание и эмпирический анализ LLM

## Что нужно сделать

### 1) Развернуть 3 разные LLM из разных семейств

Используйте **vLLM**, **SGLang**, **Ollama** или др. (в зависимости от ваших предпочтений и ресурсов). С их помощью необходимо развернуть 3 модели из **разных семейств**, например:
- Qwen
- Llama
- Mistral

Разрешены квантованные варианты (например, в Ollama), если ресурсов мало.

(ОБЯЗАТЕЛЬНО ОpenAI-совместимый REST).

---

### 2) Подготовить 3 тестовых запроса под разные типы задач

Сделайте **три разнотипных промпта** (на русском):

* **P1: генерация** (например, вежливое письмо / краткий пресс-релиз).
* **P2: классификация** (заранее задайте фиксированный список меток, напр. `["Billing","Tech support","Sales"]` и короткие входные тексты).
* **P3: извлечение/суммаризация/переформулирование** (извлечь поля из описания товара, сделать краткое резюме и т.п.).


---

### 3) Сгенерировать ответы каждой LLM в двух режимах

Для **каждой модели** и **каждого из 3 промптов** сделайте два прогона:

* **Базовый** — *без изменений гиперпараметров* (дефолты движка).
* **Тюнинг** — *измените минимум 2 гиперпараметра* из списка:

  * `temperature`, `max_tokens` (или `num_predict` в Ollama),
  * `top_p` / `top_k` (если поддерживается),
  * `repetition_penalty` / `repeat_penalty`.

---

### 4) Сохранить все ответы и провести эмпирический анализ

Сохраните **все прогоны** (модель × промпт × {A,B}) и подготовьте краткий анализ влияния гиперпараметров:

* Сравните: **длину ответа в токенах LLM**, **точность/адекватность** под задачу, **стабильность/детерминизм**, **повторяемость**, **наличие фактических ошибок/галлюцинаций**.
* По возможности зафиксируйте **время отклика**, **число токенов ввода/вывода** (если движок возвращает) и **скорость токенизации/генерации**.
* Отметьте различия дефолтов между движками (например, разные базовые temperature/top\_p).
